import cv2
import mediapipe as mp
import joblib
import numpy as np
import warnings

# üîá Suppress protobuf UserWarnings
warnings.filterwarnings("ignore", category=UserWarning)

# Load model and initialize MediaPipe
model = joblib.load("hand_sign_model.pkl")
expected_features = model.n_features_in_

mp_hands = mp.solutions.hands
hands_detector = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)
mp_drawing = mp.solutions.drawing_utils

# Start webcam
cap = cv2.VideoCapture(0)

while True:
    success, frame = cap.read()
    frame = cv2.flip(frame, 1)  # mirror image
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands_detector.process(rgb)

    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            lmList = [[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]

            # Dynamically extract x,y or x,y,z depending on model
            flat_landmarks = []
            for lm in lmList:
                if expected_features == 42:
                    flat_landmarks.extend([lm[0], lm[1]])        # x, y
                elif expected_features == 63:
                    flat_landmarks.extend([lm[0], lm[1], lm[2]]) # x, y, z

            if len(flat_landmarks) == expected_features:
                prediction = model.predict([flat_landmarks])[0]

                # Draw results
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                x = int(lmList[0][0] * frame.shape[1])
                y = int(lmList[0][1] * frame.shape[0])
                cv2.putText(frame, prediction, (x, y - 20),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            else:
                cv2.putText(frame, "Invalid landmark size", (50, 50),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

    cv2.imshow("Sign Language Recognition", frame)
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()












# --- train_model.py ---
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib
import os

# Step 1: Fix header if missing
csv_path = "hand_signs.csv"
if not os.path.isfile(csv_path):
    raise FileNotFoundError("‚ùå CSV file not found. Make sure 'hand_signs.csv' exists.")

# Load raw CSV and fix header if needed
df_raw = pd.read_csv(csv_path, header=None)
if 'label' not in df_raw.iloc[0].values:
    columns = [f"x{i}" for i in range(21)] + [f"y{i}" for i in range(21)] + ["label"]
    df_raw.columns = columns
    df_raw = df_raw[1:]  # remove previous first row
    df_raw.to_csv(csv_path, index=False)
    print("‚úÖ Fixed CSV header.")

# Step 2: Load cleaned data
df = pd.read_csv(csv_path)
if 'label' not in df.columns:
    raise ValueError("‚ùå 'label' column still not found. Check your CSV file manually.")

print("[INFO] Label counts:\n", df['label'].value_counts())

X = df.drop("label", axis=1)
y = df["label"]

# Step 3: Train-test split
if len(df) < 2:
    raise ValueError("‚ùå Not enough data to train. Collect more samples.")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Train model
model = KNeighborsClassifier(n_neighbors=min(3, len(X_train)))
model.fit(X_train, y_train)

# Step 5: Evaluate
y_pred = model.predict(X_test)
print("[INFO] Accuracy:", accuracy_score(y_test, y_pred))
print("[INFO] Report:\n", classification_report(y_test, y_pred))

# Step 6: Save model
joblib.dump(model, "hand_sign_model.pkl")
print("‚úÖ Model saved as 'hand_sign_model.pkl'")










import os
import sys
import ctypes

# Set TF + absl suppression
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

# Hide native stderr (for TensorFlow Lite, absl, etc.)
def suppress_native_stderr():
    if os.name == 'nt':
        # Windows
        kernel32 = ctypes.windll.kernel32
        kernel32.SetStdHandle(-12, 0)  # -12 = STDERR
    else:
        # Unix/Linux
        sys.stderr = open(os.devnull, 'w')

suppress_native_stderr()

import cv2
import mediapipe as mp
import pandas as pd

# Setup Mediapipe
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)
mp_draw = mp.solutions.drawing_utils

# Setup webcam
cap = cv2.VideoCapture(0)

# Data storage
data = []
label = input("Enter the sign label (e.g., Hello, A, ThankYou): ")

print("[INFO] Press 's' to save landmark, 'q' to quit")

while True:
    success, frame = cap.read()
    frame = cv2.flip(frame, 1)
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb)

    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # Flatten landmarks
            landmarks = []
            for lm in hand_landmarks.landmark:
                landmarks.append(lm.x)
                landmarks.append(lm.y)

            # Wait for keypress to save
            key = cv2.waitKey(1)
            if key == ord('s'):
                data.append(landmarks + [label])
                print(f"[SAVED] Sample saved for label: {label}")

    cv2.putText(frame, f"Label: {label}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.imshow("Hand Data Collector", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release
cap.release()
cv2.destroyAllWindows()

# Save to CSV
df = pd.DataFrame(data)
df.to_csv("hand_signs.csv", mode='a', index=False, header=False)
print(f"[INFO] Data saved to hand_signs.csv with label: {label}")






import pandas as pd

# Load the collected gesture data
df = pd.read_csv("hand_signs.csv")

# Check if the 'label' column exists
if "label" not in df.columns:
    raise ValueError("‚ùå 'label' column not found in CSV. Check your file.")

# Count samples per gesture label
label_counts = df["label"].value_counts()

# Display results
print("‚úÖ Samples per gesture label:\n")
print(label_counts)

# Total number of collected samples
total_samples = len(df)
print(f"\nüì¶ Total samples collected: {total_samples}")







import pandas as pd

# Load CSV
df = pd.read_csv("hand_signs.csv")

# Show all unique labels
print("‚úÖ Available signs:", df['label'].unique())

# Sign you want to delete
sign_to_remove = input("Enter the label you want to delete: ")

# Filter out the sign
df_filtered = df[df['label'] != sign_to_remove]

# Save back
df_filtered.to_csv("hand_signs.csv", index=False)

print(f"‚úÖ All samples for '{sign_to_remove}' have been removed.")
print("Remaining sign counts:\n", df_filtered['label'].value_counts())